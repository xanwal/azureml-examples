{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'nlp' from 'spacy' (/home/alwallace/miniconda3/envs/spacy/lib/python3.8/site-packages/spacy/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/v-alwallace/ms/azureml-examples/scratch/docker/scratch3.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/v-alwallace/ms/azureml-examples/scratch/docker/scratch3.ipynb#ch0000000vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/v-alwallace/ms/azureml-examples/scratch/docker/scratch3.ipynb#ch0000000vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/v-alwallace/ms/azureml-examples/scratch/docker/scratch3.ipynb#ch0000000vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspacy\u001b[39;00m \u001b[39mimport\u001b[39;00m nlp, DocBin\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'nlp' from 'spacy' (/home/alwallace/miniconda3/envs/spacy/lib/python3.8/site-packages/spacy/__init__.py)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from spacy import nlp, DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ner_dataset.csv',encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = list(np.ravel(np.where(~pd.isnull(df['Sentence #']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = [None] * (len(start_idx)-1)\n",
    "for (b,e),i in zip(zip(start_idx[:-1],[x-1 for x in start_idx[1:]]),range(0, (len(start_idx)-1))):\n",
    "    sent = list(df['Word'][b:e])\n",
    "    tags = [None if t=='O' else t.split('-')[1] for t in list(df['Tag'][b:e])]\n",
    "    ents = []\n",
    "    w_start = 0\n",
    "    ent = [None,None,None]\n",
    "    for w_idx in range(0,len(sent)):\n",
    "        word_len = len(sent[w_idx])\n",
    "        same_tag = False\n",
    "        tag = tags[w_idx]\n",
    "        try:\n",
    "            if tags[w_idx+1] == tag and tag is not None:\n",
    "                same_tag = True\n",
    "        except:\n",
    "            pass \n",
    "        if same_tag:\n",
    "            if ent[0] is None:\n",
    "                ent[0] = tag\n",
    "                ent[1] = w_start\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            if ent[0] is None:\n",
    "                ent[0] = tag\n",
    "                ent[1] = w_start\n",
    "                ent[2] = w_start + word_len\n",
    "            else:\n",
    "                ent[2] = w_start + word_len\n",
    "            if ent[0] is not None:\n",
    "                ents.append((tuple(ent)))\n",
    "            ent = [None,None,None]\n",
    "        w_start = w_start + word_len + 1\n",
    "    js[i] = {'sentence' : ' '.join(sent), \n",
    "    'entities' : ents}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"Hamas wants to build a coalition government , but Mr. Abbas 's Fatah party and the militant Islamic Jihad group have declined to join\",\n",
       " 'entities': [('org', 0, 5),\n",
       "  ('per', 50, 59),\n",
       "  ('geo', 63, 68),\n",
       "  ('geo', 92, 105)]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "# the DocBin will store the example documents\n",
    "db = DocBin()\n",
    "for dic in js:\n",
    "    text = dic['sentence']\n",
    "    annotations = dic['entities']\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for label, start, end in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./train.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0104a8488bc9ed808c33ce2a90fbef16b15548a9ffd38d90be3a5977cd96a42e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('spacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
