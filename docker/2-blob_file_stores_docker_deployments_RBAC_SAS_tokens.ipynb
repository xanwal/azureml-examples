{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Azure blob and file stores using RBAC, SAS tokens, and the Python Storage SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we explore role-, token-, and filesystem-based access to File Stores and Blob Storage using customized images and environments for inference servers. RBAC and SAS offer complementary ways to control access to resources and enable managed entities such as Managed Online Endpoints to authenticate themselves to other services. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To use Azure Machine Learning, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n",
    "\n",
    "* Install and configure the [Python SDK v2](sdk/setup.sh).\n",
    "\n",
    "* You must have an Azure resource group, and you (or the service principal you use) must have Contributor access to it.\n",
    "\n",
    "* You must have an Azure Machine Learning workspace. \n",
    "\n",
    "* You must have an Azure Secure Container registry. One is created automatically created for a workspace without one upon first usage, however in this example we explicitly reference the container registry by name, so you need it beforehand. You can create one through the Azure Portal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '<YOUR_SUBSCRIPTION_ID>'\n",
    "resource_group = '<YOUR_RESOURCE_GROUP>'\n",
    "workspace = '<YOUR_WORKSPACE>'\n",
    "container_registry_name = '<YOUR_CONTAINER_REGISTRY>'\n",
    "storage_account_name = '<YOUR_STORAGE_ACCOUNT_NAME>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '6fe1c377-b645-4e8e-b588-52e57cc856b2'\n",
    "resource_group = 'v-alwallace-test'\n",
    "workspace = 'valwallace'\n",
    "container_registry_name = 'valwallaceskr'\n",
    "existing_storage_account_name = 'valwallacestorage'\n",
    "new_storage_account_name = 'awstoracc'\n",
    "new_file_share_name = 'endptshare'\n",
    "new_container_name = \"endptcontainer\"\n",
    "new_blob_name = \"endptblob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ml import MLClient\n",
    "from azure.storage.blob import BlobClient, BlobSasPermissions,BlobServiceClient, ContainerSasPermissions, generate_container_sas\n",
    "from azure.mgmt.storage.v2021_09_01 import StorageManagementClient\n",
    "from azure.mgmt.storage.v2021_09_01.models import StorageAccountCreateParameters, Sku, FileShare, BlobContainer\n",
    "from azure.mgmt.containerregistry.v2021_12_01_preview import ContainerRegistryManagementClient\n",
    "from azure.mgmt.authorization.v2021_03_01_preview import AuthorizationManagementClient\n",
    "from azure.ml.entities import ManagedOnlineDeployment, ManagedOnlineEndpoint\n",
    "from azure.identity import DefaultAzureCredential,InteractiveBrowserCredential\n",
    "from random import randint\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\n",
    "storage_client = StorageManagementClient(DefaultAzureCredential(),subscription_id)\n",
    "cr_client = ContainerRegistryManagementClient(DefaultAzureCredential(),subscription_id)\n",
    "auth_client = AuthorizationManagementClient(DefaultAzureCredential(),subscription_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "# Required\n",
    "deployment_name = 'docker-storage'\n",
    "container_name = 'docker-storage'\n",
    "# Optional\n",
    "endpoint_name = f'docker-storage-{randint(1e3,1e7)}'\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(name=endpoint_name)\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)\n",
    "\n",
    "# Check endpoint status\n",
    "print(f'Endpoint Status: {endpoint.provisioning_state}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allow a managed endpoint to access a file store with RBAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a storage client to enable the initial privisioning of new storage resources.\n",
    "\n",
    "`StorageManagementClient(DefaultAzureCredential(),subscription_id)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new storage account and file share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new storage account\n",
    "response = storage_client.storage_accounts.begin_create(\n",
    "                resource_group,\n",
    "                new_storage_account_name,\n",
    "                StorageAccountCreateParameters(\n",
    "                    sku=Sku(name='Standard_LRS'),\n",
    "                    kind='Storage',\n",
    "                    location='eastus2'))\n",
    "\n",
    "stor_acct_details = response.result()\n",
    "\n",
    "# Create a file share\n",
    "storage_client.file_shares.create(resource_group,\n",
    "                                  new_storage_account_name,\n",
    "                                  new_file_share_name,\n",
    "                                  file_share=FileShare())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect properties, principal IDs and account IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the new file share\n",
    "new_fs = storage_client.file_shares.get(resource_group,\n",
    "                                        new_storage_account_name,\n",
    "                                        new_file_share_name) \n",
    "# View storage properties\n",
    "storage_acct_properties = storage_client.storage_accounts.get_properties(resource_group, \n",
    "                                                                         new_storage_account_name)\n",
    "\n",
    "# Get system identity\n",
    "system_identity = endpoint.identity.principal_id\n",
    "storage_id = storage_acct_properties.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a role assigment for the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the service principal to allow the endpoint to connect to Samba\n",
    "!az role assignment create --assignee-object-id {system_identity} --assignee-principal-type ServicePrincipal --role \"Storage File Data SMB Share Reader\" --scope {storage_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a blob container with Shared Access Signature (SAS) access\n",
    "Begin with the general storage client and use it to retrieve the keys to the storage account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta \n",
    "container = storage_client.blob_containers.create(resource_group,\n",
    "                                                  new_storage_account_name,\n",
    "                                                  new_container_name,\n",
    "                                                  BlobContainer())\n",
    "\n",
    "storage_url = storage_acct_properties.primary_endpoints.blob\n",
    "\n",
    "keys = storage_client.storage_accounts.list_keys(resource_group, \n",
    "                                                 new_storage_account_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a storage account key to generate a SAS token for a blob container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_container_sas = generate_container_sas(\n",
    "                                new_storage_account_name,\n",
    "                                new_container_name,\n",
    "                                account_key=keys.keys[0].value,\n",
    "                                expiry = (datetime.utcnow() + timedelta(hours=1)),\n",
    "                                permission=ContainerSasPermissions(\n",
    "                                    read=True,\n",
    "                                    add=True,\n",
    "                                    list=True,\n",
    "                                    tag=True,\n",
    "                                    move=True,\n",
    "                                    create=True,\n",
    "                                    write=True,\n",
    "                                    delete=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a blob service client to generate admin blob and container clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_blobserv_client = BlobServiceClient(storage_url,\n",
    "                                               privileged_container_sas)\n",
    "privileged_container_client = privileged_blobserv_client.get_container_client(new_container_name)\n",
    "privileged_blob_client = privileged_blobserv_client.get_blob_client(new_container_name,\n",
    "                                                                    new_blob_name)\n",
    "\n",
    "# Upload a trained model to blob storage\n",
    "if not privileged_blob_client.exists: \n",
    "    with open('docker_storage/sklearn_regression_model.pkl', 'rb') as f:\n",
    "        privileged_blob_client.upload_blob(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get read only SAS tokens to provide to consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readonly_container_sas = generate_container_sas(\n",
    "                            new_storage_account_name,\n",
    "                            new_container_name,\n",
    "                            account_key=keys.keys[0].value,\n",
    "                            expiry = datetime.today() + timedelta(days=30),\n",
    "                            permission=BlobSasPermissions(read=True))\n",
    "                            \n",
    "readonly_blobserv_client = BlobServiceClient(storage_url,\n",
    "                                             readonly_container_sas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access a blob from a container with Azure storage clients and SAS tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile signatures and sensitive environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('storageclient.config', 'wb') as f:\n",
    "    json.dump({'account': new_storage_account_name,\n",
    "                'container': new_container_name, \n",
    "                'blob': new_blob_name, \n",
    "                'credential': readonly_container_sas},\n",
    "                file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the score.py file to pull a scored model from the blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "config = json.load('/run/secrets/storageclient.config')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "client = BlobClient(config['account'],\n",
    "                    config['container'],\n",
    "                    config['blob'],\n",
    "                    credential=config['credential'])\n",
    "```\n",
    "```python\n",
    "if client.exists: \n",
    "    with open(model_path, 'wb') as f:\n",
    "        model = pickle.loads(f.download_blob().read_all())\n",
    "else: \n",
    "    raise FileNotFoundError('No model was found in blob storage')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obfuscate the configuration with Docker secrets and push to ACR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login \n",
    "!az acr login --name {container_registry_name}\n",
    "!docker build --secret id=storageclientconfig,src=storageclient.config -t  {container_registry_name}.azurecr.io/storage-client . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the deployment with YAML \n",
    "This deployment has additional Conda dependencies. We update default values below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```YAML\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "name: storage-client \n",
    "endpoint_name: endpoint-name\n",
    "code_configuration: \n",
    "  code: \".\"\n",
    "  scoring_script: score.py\n",
    "environment:\n",
    "  image: container_registry.azurecr.io/docker-conda:latest\n",
    "  conda_file : /docker_storage/conda.yml \n",
    "instance_type: Standard_F2s_v2\n",
    "instance_count: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('deployment_local.yml','r') as f:\n",
    "    deployment_yaml = yaml.safe_load(f)\n",
    "\n",
    "deployment_yaml['endpoint_name'] = endpoint_name\n",
    "deployment_yaml['environment']['image'] = f'{container_registry_name}.azurecr.io/{container_name}:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the endpoint and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = ManagedOnlineEndpoint(name=f{endpoint_name})\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)\n",
    "deployment = ManagedOnlineDeployment.load(os.path.join(deployment_name,'deployment.yml'))\n",
    "ml_client.online_deployments.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_token = ml_client.online_endpoints.list_keys(endpoint_name).primary_key\n",
    "endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "scoring_uri = endpoint.scoring_uri\n",
    "\n",
    "with open('sample-request.json') as f:\n",
    "    data = json.loads(f.read())\n",
    "ml_client.online_endpoints.invoke(endpoint.name,data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a90ecae7da317becffff9d469f162817a17f540c050fa4ba8f20279bd68504c1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aml_cp38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
