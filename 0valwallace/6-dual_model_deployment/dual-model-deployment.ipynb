{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy two models in the same online deployment\n",
    "In this sample, we build an environment from scratch, write code for the server including a `score.py` file and a basic custom module, test the deployment locally, and deploy to the cloud. We'll see how the `score.py` file can be used as an entrypoint for multiple models and custom code. \n",
    "\n",
    "We'll use two simple binary image classification models called `cats` and `horses` that we create in the example [Train two image classification models in one pipeline](). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment \n",
    "To build the environment, we start with the Azure minimal Ubuntu 18.04 image. The inference server is pre-loaded and we will install the required additional libraries `libpng` via apt and packages `tensorflow`, `pillow`, and `keras-preprocessing` via pip in the Dockerfile.\n",
    "## Inputs\n",
    "### Dockerfile\n",
    "```dockerfile\n",
    "FROM \"mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest\"\n",
    "\n",
    "USER root\n",
    "RUN apt-get update\n",
    "RUN apt-get install -y libpng-dev\n",
    "\n",
    "USER dockeruser\n",
    "\n",
    "COPY requirements.txt /tmp/requirements.txt\n",
    "\n",
    "RUN pip install -r /tmp/requirements.txt\n",
    "```\n",
    "### requirements.txt\n",
    "```\n",
    "tensorflow-gpu>=2.8, <2.9\n",
    "keras>= 2.8, <2.9\n",
    "pillow>= 9.1, <9.2\n",
    "keras-preprocessing>=1.1, <1.2\n",
    "``` \n",
    "## Build\n",
    "To build the environment, will call `az` with the environment file `environment.yaml` which contains the name of the environment `dualdeployment` as well as the directory \"deploy\" in which the Dockerfile and `requirements.txt` file is located. \n",
    "\n",
    "```yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: dualdeploy-env\n",
    "build:\n",
    "  path: ./deploy\n",
    "```\n",
    "Build the environment with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml environment create --file environment.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure code \n",
    "An online deployment requires a scoring file (usually called `score.py`), which should have an `init` method called once and a `run` method called for every request. Our `score.py` file follows this pattern. However, rather than handle the models entirely in `score.py` we import a minimal custom module `model.py`, which contains a handler for the `cats` and `horses` models. The `score.py` file can act as an entrypoint for extensive custom behavior by using a similar pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score.py (snippet)\n",
    "```python\n",
    "def init(): \n",
    "    global handle\n",
    "    handle = Handle(os.getenv(\"AZUREML_MODEL_DIR\"))\n",
    "\n",
    "    logging.info(\"Init complete\")\n",
    "\n",
    "def run(raw_data): \n",
    "    logging.info(\"Request received\")\n",
    "    try:\n",
    "        response = handle(raw_data)\n",
    "        logging.info(\"Request processed\")\n",
    "        return response\n",
    "    except ValueError as e:\n",
    "        logging.info(\"Request failed\")\n",
    "        logging.info(str(e))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py (snippet)\n",
    "\n",
    "```python\n",
    "class Handle(object):\n",
    "    def __init__(self, azureml_model_dir):\n",
    "        self.azureml_model_dir = azureml_model_dir\n",
    "        self.models = {'cats' : Cats(azureml_model_dir), \n",
    "                       'horses' : Horses(azureml_model_dir)}\n",
    "        self.valid_categories = set(self.models.keys())             \n",
    "\n",
    "    def __call__(self, raw_data):\n",
    "        raw_data = json.loads(raw_data)\n",
    "        try:\n",
    "            image = raw_data[\"image\"]\n",
    "            category = raw_data[\"category\"]\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Request must contain fields 'image' and 'category'\")\n",
    "        if category in self.valid_categories:\n",
    "            return self.models[category].score(image).tolist()\n",
    "        else:\n",
    "            raise ValueError(\"No model for category\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy\n",
    "Before we deploy to Azure, we'll first and test and deploy on our local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a local endpoint\n",
    "The YAML file contains just \"name\" and \"auth_mode.\" \n",
    "```yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json\n",
    "name: dualdeploy-endpt\n",
    "version: 1\n",
    "auth_mode: key\n",
    "```\n",
    "Deploy the local online endpoint with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml online-endpoint create --file endpoint.yaml --local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the deployment\n",
    "The deployment YAML file integrates the endpoint, environment, code, and model:\n",
    "```yaml \n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "name: dualdeploy-dplmt\n",
    "endpoint_name: dualdeploy-endpt \n",
    "model:\n",
    "  name: dualdeploy\n",
    "  path: ./model/\n",
    "code_configuration:\n",
    "  code: ./deploy/code\n",
    "  scoring_script: score.py\n",
    "environment: azureml:dualdeploy-env:1\n",
    "instance_type: Standard_F2s_v2\n",
    "instance_count: 1\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml online-deployment create --file deployment.yaml --local true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the deployment fails, try checking the logs with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml online-deployment get-logs --name cathorse --endpoint-name cathorse-endpoint  --local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the deployment\n",
    "In order to facilitate calling the endpoint with `invoke`, the endpoint can accept images formatted as `.json` data. The json must have the keys \"category\" and \"image\".\n",
    "\n",
    "The directory `test-data` has directories for \"cats\", \"horses\", \"not_cats\", and \"not_horses\", each containing 5 png and json files selected from the test dataset. Let's try a few.\n",
    "\n",
    "If your deployment fails upon invoking, check the logs with the command above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "\"[[0.9998284578323364]]\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint invoke --name dualdeploy-endpt --local true --request-file test_data/cats/0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "\"[[1.348734679496033e-09]]\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint invoke --name dualdeploy-endpt --local true --request-file test_data/not_cats/0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horse Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "\"[[0.999983549118042]]\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint invoke --name dualdeploy-endpt --local true --request-file test_data/horses/0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not Horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "\"[[0.00010628611198626459]]\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint invoke --name dualdeploy-endpt --local true --request-file test_data/not_horses/0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to Azure\n",
    "Finally, we can push our deployment to Azure with no changes to the YAML by removing the `--local` flags.\n",
    "\n",
    "## Delete the local endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "Are you sure you want to perform this operation? (y/n): ^C\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint delete --name dualdeploy-endpt --local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an online endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "{\n",
      "  \"auth_mode\": \"key\",\n",
      "  \"id\": \"/subscriptions/6fe1c377-b645-4e8e-b588-52e57cc856b2/resourceGroups/v-alwallace-test/providers/Microsoft.MachineLearningServices/workspaces/valwallace/onlineEndpoints/dualdeploy-endpt\",\n",
      "  \"identity\": {\n",
      "    \"principal_id\": \"21dabe56-1ba8-459f-8564-8e231a732509\",\n",
      "    \"tenant_id\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "    \"type\": \"system_assigned\"\n",
      "  },\n",
      "  \"location\": \"eastus2\",\n",
      "  \"name\": \"dualdeploy-endpt\",\n",
      "  \"properties\": {\n",
      "    \"AzureAsyncOperationUri\": \"https://management.azure.com/subscriptions/6fe1c377-b645-4e8e-b588-52e57cc856b2/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:4de1aac5-5d2e-4819-8298-47038d76b5ae:36df4696-22f0-4a9d-a4d2-460580638b2d?api-version=2021-10-01\",\n",
      "    \"azureml.onlineendpointid\": \"/subscriptions/6fe1c377-b645-4e8e-b588-52e57cc856b2/resourcegroups/v-alwallace-test/providers/microsoft.machinelearningservices/workspaces/valwallace/onlineendpoints/dualdeploy-endpt\"\n",
      "  },\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"v-alwallace-test\",\n",
      "  \"scoring_uri\": \"https://dualdeploy-endpt.eastus2.inference.ml.azure.com/score\",\n",
      "  \"swagger_uri\": \"https://dualdeploy-endpt.eastus2.inference.ml.azure.com/swagger.json\",\n",
      "  \"tags\": {},\n",
      "  \"traffic\": {}\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint create --file endpoint.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an online deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-deployment' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "Check: endpoint dualdeploy-endpt exists\n",
      "\u001b[32mUploading code (0.01 MBs): 100%|█████████| 7649/7649 [00:00<00:00, 40959.30it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading model (14.35 MBs): 100%|█| 14351714/14351714 [00:07<00:00, 1945970.14i\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "Creating/updating online deployment dualdeploy-dplmt ..........................................................Done (5m 25s)\n",
      "{\n",
      "  \"app_insights_enabled\": false,\n",
      "  \"code_configuration\": {\n",
      "    \"code\": \"/subscriptions/6fe1c377-b645-4e8e-b588-52e57cc856b2/resourceGroups/v-alwallace-test/providers/Microsoft.MachineLearningServices/workspaces/valwallace/codes/a8370bb8-1301-4d53-841a-0bd425f5aad1/versions/1\",\n",
      "    \"scoring_script\": \"score.py\"\n",
      "  },\n",
      "  \"endpoint_name\": \"dualdeploy-endpt\",\n",
      "  \"environment\": \"azureml:/subscriptions/6fe1c377-b645-4e8e-b588-52e57cc856b2/resourceGroups/v-alwallace-test/providers/Microsoft.MachineLearningServices/workspaces/valwallace/environments/dualdeploy-env/versions/1\",\n",
      "  \"environment_variables\": {},\n",
      "  \"instance_count\": 1,\n",
      "  \"instance_type\": \"Standard_F2s_v2\",\n",
      "  \"model\": \"azureml:/subscriptions/6fe1c377-b645-4e8e-b588-52e57cc856b2/resourceGroups/v-alwallace-test/providers/Microsoft.MachineLearningServices/workspaces/valwallace/models/dualdeploy/versions/1\",\n",
      "  \"name\": \"dualdeploy-dplmt\",\n",
      "  \"properties\": {},\n",
      "  \"tags\": {},\n",
      "  \"type\": \"managed\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-deployment create --file deployment.yaml --all-traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "\"[[0.9987295866012573]]\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint invoke --name dualdeploy-endpt --request-file test_data/cats/1.json"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50db1dce3900200bed9bfd600df88d2ae354b85acd9708fa0a0be5ff9bc29e40"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
