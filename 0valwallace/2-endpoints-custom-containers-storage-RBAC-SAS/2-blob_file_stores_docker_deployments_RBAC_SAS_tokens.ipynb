{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Azure blob and file stores using RBAC, SAS tokens, and the Python Storage SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we create a new storage account and explore role and token-based access to File Stores and Blob Storage beyond the Workspace. Role Based Access Control (RBAC) and Secure Access Signatures (SAS) offer ways to control access to data and enable managed entities such as Managed Online Endpoints to authenticate themselves to other services. To access datastores from online endpoints in simple scenarios without access controls, see [Mount Workspace Storage in a Managed Online Endpoint](). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To use Azure Machine Learning, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n",
    "\n",
    "* Install and configure the [Python SDK v2](sdk/setup.sh).\n",
    "\n",
    "* You must have an Azure resource group, and you (or the service principal you use) must have Contributor access to it.\n",
    "\n",
    "* You must have an Azure Machine Learning workspace. \n",
    "\n",
    "* You must have an Azure Secure Container registry. One is created automatically created for a workspace without one upon first usage, however in this example we explicitly reference the container registry by name, so you need it beforehand. You can create one through the Azure Portal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import MLClient\n",
    "from azure.storage.blob import BlobClient, BlobSasPermissions,BlobServiceClient, ContainerSasPermissions, generate_container_sas\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "from azure.mgmt.storage.models import StorageAccountCreateParameters, Sku, FileShare, BlobContainer\n",
    "from azure.mgmt.containerregistry import ContainerRegistryManagementClient\n",
    "from azure.mgmt.authorization import AuthorizationManagementClient\n",
    "from azure.ml.entities import ManagedOnlineDeployment, ManagedOnlineEndpoint\n",
    "from azure.identity import DefaultAzureCredential,InteractiveBrowserCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter details of your AML Workspace\n",
    "subscription_id = '<YOUR_SUBSCRIPTION_ID>'\n",
    "resource_group = '<YOUR_RESOURCE_GROUP>'\n",
    "workspace = '<YOUR_WORKSPACE>'\n",
    "# \n",
    "container_registry_name = '<YOUR_CONTAINER_REGISTRY>'\n",
    "storage_account_name = '<YOUR_STORAGE_ACCOUNT_NAME>'\n",
    "# \n",
    "new_storage_account_name = '<NEW_STORAGE_ACCOUNT_NAME>'\n",
    "new_file_share_name = '<NEW_FILE_SHARE_NAME>'\n",
    "new_container_name = \"<NEW_CONTAINER_NAME>\"\n",
    "new_blob_name = \"<NEW_BLOB_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '6fe1c377-b645-4e8e-b588-52e57cc856b2'    \n",
    "resource_group = 'v-alwallace-test'\n",
    "workspace = 'valwallace'\n",
    "container_registry_name = 'valwallaceskr'\n",
    "existing_storage_account_name = 'valwallacestorage'\n",
    "new_storage_account_name = 'awstoracc'\n",
    "new_file_share_name = 'endptshare'\n",
    "new_container_name = \"endptcontainer\"\n",
    "new_blob_name = \"endptblob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configure workspace details and get Azure handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DefaultAzureCredential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21994/2870246928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDefaultAzureCredential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubscription_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstorage_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStorageManagementClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDefaultAzureCredential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubscription_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DefaultAzureCredential' is not defined"
     ]
    }
   ],
   "source": [
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\n",
    "storage_client = StorageManagementClient(DefaultAzureCredential(),subscription_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "# Required\n",
    "deployment_name = 'docker-storage'\n",
    "container_name = 'docker-storage'\n",
    "# Optional\n",
    "endpoint_name = f'docker-storage-{randint(1e3,1e7)}'\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(name=endpoint_name)\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)\n",
    "\n",
    "# Check endpoint status\n",
    "print(f'Endpoint Status: {endpoint.provisioning_state}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allow a managed endpoint to access a file store with RBAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a storage client to enable the initial privisioning of new storage resources.\n",
    "\n",
    "`StorageManagementClient(DefaultAzureCredential(),subscription_id)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new storage account and file share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new storage account\n",
    "response = storage_client.storage_accounts.begin_create(\n",
    "                resource_group,\n",
    "                new_storage_account_name,\n",
    "                StorageAccountCreateParameters(\n",
    "                    sku=Sku(name='Standard_LRS'),\n",
    "                    kind='Storage',\n",
    "                    location='eastus2'))\n",
    "\n",
    "stor_acct_details = response.result()\n",
    "\n",
    "# Create a file share\n",
    "storage_client.file_shares.create(resource_group,\n",
    "                                  new_storage_account_name,\n",
    "                                  new_file_share_name,\n",
    "                                  file_share=FileShare())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect properties, principal IDs and account IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the new file share\n",
    "new_fs = storage_client.file_shares.get(resource_group,\n",
    "                                        new_storage_account_name,\n",
    "                                        new_file_share_name) \n",
    "# View storage properties\n",
    "storage_acct_properties = storage_client.storage_accounts.get_properties(resource_group, \n",
    "                                                                         new_storage_account_name)\n",
    "\n",
    "# Get system identity\n",
    "system_identity = endpoint.identity.principal_id\n",
    "storage_id = storage_acct_properties.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a role assigment for the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the service principal to allow the endpoint to connect to Samba\n",
    "!az role assignment create --assignee-object-id {system_identity} --assignee-principal-type ServicePrincipal --role \"Storage File Data SMB Share Reader\" --scope {storage_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a blob container with Shared Access Signature (SAS) access\n",
    "Begin with the general storage client and use it to retrieve the keys to the storage account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta \n",
    "container = storage_client.blob_containers.create(resource_group,\n",
    "                                                  new_storage_account_name,\n",
    "                                                  new_container_name,\n",
    "                                                  BlobContainer())\n",
    "\n",
    "storage_url = storage_acct_properties.primary_endpoints.\n",
    "\n",
    "keys = storage_client.storage_accounts.list_keys(resource_group, \n",
    "                                                 new_storage_account_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a storage account key to generate a SAS token for a blob container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_permissions = ContainerSasPermissions(\n",
    "    read=True, add=True, list=True, tag=True,\n",
    "    move=True, create=True,write=True, delete=True)\n",
    "\n",
    "privileged_container_sas = generate_container_sas(\n",
    "                                new_storage_account_name,\n",
    "                                new_container_name,\n",
    "                                account_key=keys.keys[0].value,\n",
    "                                expiry = (datetime.utcnow() + timedelta(hours=1)),\n",
    "                                permission=container_permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a blob service client to generate admin blob and container clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_blobserv_client = BlobServiceClient(storage_url,\n",
    "                                               privileged_container_sas)\n",
    "privileged_container_client = privileged_blobserv_client.get_container_client(new_container_name)\n",
    "privileged_blob_client = privileged_blobserv_client.get_blob_client(new_container_name,\n",
    "                                                                    new_blob_name)\n",
    "\n",
    "# Upload a trained model to blob storage\n",
    "if not privileged_blob_client.exists: \n",
    "    with open('docker_storage/sklearn_regression_model.pkl', 'rb') as f:\n",
    "        privileged_blob_client.upload_blob(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get read-only SAS tokens to provide to consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readonly_container_sas = generate_container_sas(\n",
    "                            new_storage_account_name,\n",
    "                            new_container_name,\n",
    "                            account_key=keys.keys[0].value,\n",
    "                            expiry = datetime.today() + timedelta(days=30),\n",
    "                            permission=BlobSasPermissions(read=True))\n",
    "                            \n",
    "readonly_blobserv_client = BlobServiceClient(storage_url,\n",
    "                                             readonly_container_sas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access a blob from a container with Azure storage clients and SAS tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile signatures and sensitive environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('storageclient.config', 'wb') as f:\n",
    "    json.dump({'account': new_storage_account_name,\n",
    "                'container': new_container_name, \n",
    "                'blob': new_blob_name, \n",
    "                'credential': readonly_container_sas},\n",
    "                file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the score.py file to pull a scored model from the blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "config = json.load('/run/secrets/storageclient.config')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "client = BlobClient(config['account'],\n",
    "                    config['container'],\n",
    "                    config['blob'],\n",
    "                    credential=config['credential'])\n",
    "```\n",
    "```python\n",
    "if client.exists: \n",
    "    with open(model_path, 'wb') as f:\n",
    "        model = pickle.loads(f.download_blob().read_all())\n",
    "else: \n",
    "    raise FileNotFoundError('No model was found in blob storage')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obfuscate the configuration with Docker secrets and push to ACR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login \n",
    "!az acr login --name {container_registry_name}\n",
    "!docker build --secret id=storageclientconfig,src=storageclient.config -t  {container_registry_name}.azurecr.io/storage-client . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the deployment with YAML \n",
    "This deployment has additional Conda dependencies. We update default values below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```YAML\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "name: storage-client \n",
    "endpoint_name: endpoint-name\n",
    "code_configuration: \n",
    "  code: \".\"\n",
    "  scoring_script: score.py\n",
    "environment:\n",
    "  image: container_registry.azurecr.io/docker-conda:latest\n",
    "  conda_file : /docker_storage/conda.yml \n",
    "instance_type: Standard_F2s_v2\n",
    "instance_count: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('deployment_local.yml','r') as f:\n",
    "    deployment_yaml = yaml.safe_load(f)\n",
    "\n",
    "deployment_yaml['endpoint_name'] = endpoint_name\n",
    "deployment_yaml['environment']['image'] = f'{container_registry_name}.azurecr.io/{container_name}:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the endpoint and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "endpoint = ManagedOnlineEndpoint(name=f'{endpoint_name}')\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)\n",
    "endpoint.traffic = \n",
    "deployment = ManagedOnlineDeployment.load(os.path.join(deployment_name,'deployment.yml'))\n",
    "ml_client.online_deployments.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_token = ml_client.online_endpoints.list_keys(endpoint_name).primary_key\n",
    "endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "scoring_uri = endpoint.scoring_uri\n",
    "\n",
    "with open('sample-request.json') as f:\n",
    "    data = json.loads(f.read())\n",
    "ml_client.online_endpoints.invoke(endpoint.name, data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a90ecae7da317becffff9d469f162817a17f540c050fa4ba8f20279bd68504c1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aml_cp38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
